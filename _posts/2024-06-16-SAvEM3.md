---
title: 'SAvEM3: Pretrained and Distilled Models for General-purpose 3D Neuron Reconstruction'
description: 'We introduce SAEM2-SAvEM3 pipeline for general-purpose neuron reconstruction, which extends general-purpose auxiliary tasks for SAM and lifts into the 3D U-Net by full-stage distillation.'
author: hao
date: 2024-06-16 00:00:00 +0800
categories: [Conference, Connectomics Conference 2024]
tags: [neuron, foundation model, distillation, vEM]
math: true
pin: true
---

**Hao Zhai**\*, Jinyue Guo\*, Yanchao Zhang\*, Jing Liu, Hua Han

*Key Laboratory of Brain Cognition and Brain-inspired Intelligence Technology, Institute of Automation, Chinese Academy of Science* <br>
*School of Future Technology, School of Artificial Intelligence, University of Chinese Academy of Sciences*

### Abstract

With an explosion in the uptake of volume electron microscopy (vEM) across neuroscience and fast-paced advances in imaging protocols, it is timely to introduce general-purpose automation for newly generated large-scale vEM datasets. Recent vision foundation models (*e.g.*, SAM) set a new benchmark for the generalization of 2D segmentation. However, SAM has difficulty handling neurons that are densely packed into 3D volumes. To overcome this obstacle, we consider solutions from both data and model aspects. In terms of data, we introduce a data engine to optimize manual labeling, including (i) human-in-the-loop data cleansing and (ii) model-in-the-loop data unification. In terms of model, we present the SAEM$$^2$$-SAvEM$$^3$$ with strategies, including (i) auxiliary learning, which predicts complementary representations for SAM masks and improves performance on dense instances; (ii) full-stage distillation, which integrates ViT embeddings into a 3D U-Net, achieves 2D-to-3D lifting and model slimming at the same time; and (iii) prompt-based graph-cut, which reuses SAM prompts to assign weights of nodes and edges in the oversegmentation graph. According to evaluations of dense and large-scale sparse groundtruth neurons, the out-of-distribution performance of our pretrained-distilled models is on par with the state-of-the-art supervised and semi-supervised methods. The overall pipeline provides a possible general-purpose solution for 3D neuron reconstruction in any new vEM data. Our code will be available at [https://github.com/JackieZhai/SAvEM3](https://github.com/JackieZhai/SAvEM3).

# Motivation

Vision foundation models have recently been well developed by introducing vision transformers (Segment Anything Model, SAM) and training on extremely large datasets (SA-1B). Conceptually, they achieved state-of-the-art out-of-distribution generalization because of two interconnected necessities: a powerful model with prompt engineering and a data engine with a number of high-quality and diverse masks. However, there are still obstacles in both the model and data aspects toward general-purpose 3D neuron reconstruction in vEM or scaling connectomics.

In data aspect, there is currently no comprehensive dataset collection and unification for vEM. Meanwhile, datasets from various imaging methods, animal species and brain regions are likely to have different manual labeling styles.

In model aspect, SAM still can not segment the wiring in the brain, such as the splits and merges of dense axons, dendrites, and the homogeneous (weak semantic) plasma membrane. Besides, Micro-SAM and Tri-SAM directly use IoU or confidence scores to propagate 2D masks across (cross-section) images. How to lift from 2D SAM to 3D is thus an problem to be solved.

# Pipeline

(Fig1)

Our overall pipeline for general-purpose 3D neuron reconstruction is shown in Fig. 1. To sum up, there are two phases: SAEM$$^2$$ and SAvEM$$^3$$.
In the first phase, we exploit the collected data bank to train a 2D pretrained promptable generalist model, and the data engine iteratively optimizes data and models.
In the second phase, we employ the previously unseen data (without manual labeling) to distill a 3D U-Net specialist model for boundary maps and then do oversegmentation and agglomeration to get 3D instances. This pipeline is a possible bottom-up automated solution for any new vEM data.

## SAEM$^2$

### Data bank: diverse imaging methods and animal species

(Tab1, Fig2)

## SAvEM$^3$

# Results
